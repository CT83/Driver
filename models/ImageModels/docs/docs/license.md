### Information

The prototxt files are as they would be found on the Caffe Model zoo Github, used only as a meaningful reference for the build.

The data used to train this model comes from the ImageNet project, which distributes its database to researchers who agree to a following term of access: "Researcher shall use the Database only for non-commercial research and educational purposes." Accordingly, this model is distributed under a non-commercial license.

### BVLC model license

The Caffe models bundled by the BVLC are released for unrestricted use.

These models are trained on data from the ImageNet project and training data includes internet photos that may be subject to copyright.

Our present understanding as researchers is that there is no restriction placed on the open release of these learned model weights, since none of the original images are distributed in whole or in part. To the extent that the interpretation arises that weights are derivative works of the original copyright holder and they assert such a copyright, UC Berkeley makes no representations as to what use is allowed other than to consider our present release in the spirit of fair use in the academic mission of the university to disseminate knowledge and tools as broadly as possible without restriction.

### AlexNet

    @article{ding2014theano,
      title={Theano-based Large-Scale Visual Recognition with Multiple GPUs},
      author={Ding, Weiguang and Wang, Ruoyan and Mao, Fei and Taylor, Graham},
      journal={arXiv preprint arXiv:1412.2302},
      year={2014}
    }

Framework used: Caffe

License: BVLC model license - unrestricted use

Dataset used to train: ILSVRC-2012

### CaffeNet

    @article{ding2014theano,
      title={Theano-based Large-Scale Visual Recognition with Multiple GPUs},
      author={Ding, Weiguang and Wang, Ruoyan and Mao, Fei and Taylor, Graham},
      journal={arXiv preprint arXiv:1412.2302},
      year={2014}
    }

Framework used: Caffe

License: BVLC model license - unrestricted use

Dataset used to train: ILSVRC-2012

### GoogLeNet

    Going deeper with convolutions
    Szegedy, Christian; Liu, Wei; Jia, Yangqing; Sermanet, Pierre; Reed, Scott; Anguelov, Dragomir;
    Erhan, Dumitru; Vanhoucke, Vincent; Rabinovich, Andrew
    arXiv:1409.4842

This is an implementation of the GoogLeNet model nearly as described in Szegedy et. al. 2014, see Table 1.

### VGG-19

    @article{DBLP:journals/corr/SimonyanZ14a,
      author    = {Karen Simonyan and
                   Andrew Zisserman},
      title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
      journal   = {CoRR},
      volume    = {abs/1409.1556},
      year      = {2014},
      url       = {http://arxiv.org/abs/1409.1556},
      timestamp = {Wed, 01 Oct 2014 15:00:05 +0200},
      biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/SimonyanZ14a},
      bibsource = {dblp computer science bibliography, http://dblp.org}
    }

Framework used: Caffe

License: BVLC model license - unrestricted use

Dataset used to train: ILSVRC-2014


